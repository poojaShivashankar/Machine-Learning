{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Classification using Logistic Regression\n",
    "                 \n",
    " <p align>A linear classifier is a model used to make a classification decision based on the value of a linear combination of the characteristics.Logistic regression is one of the popular method used for classification algorithms and Logistic Regression is a statistical method for analyzing dataset in which there are one or more independent variables that determine the output. The outcome is the measure with a binary(0 and 1) dependent variable in case of binary classification.</p>\n",
    "\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the libraries necessary for our algorithm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score,cross_val_predict\n",
    "from sklearn import metrics,cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from numpy import where\n",
    "from pylab import scatter, show, legend, xlabel, ylabel\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will import the dataset and select the first two columns, which are the two features that we are using. We then normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df=pd.read_csv(\"/home/sathyanarayanan/Downloads/pima.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extracting only two features from the dataset\n",
    "Xraw=df.iloc[:,[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize the dataset for rescaling all the columns to the range 0-1\n",
    "X = sklearn.preprocessing.normalize(Xraw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating few arrays here which will hold the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assigning the Class variable in Y and declaring few variables necessary for implementation\n",
    "Y=df.iloc[:,8].values\n",
    "sigm=[]\n",
    "accuracy_matrix=[]\n",
    "coeff=[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are making 5 fold cross validation of data sets here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "#Using kFold implementation\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align> Here we are implementing our algorithm of predicting the response based on two features. Initially, we split the dataset into train and test set. We train our model using train dataset and then predict using test dataset.</p>\n",
    "<p align>The equation for logistic regression is :y = sigma(w^T * x) = 1/(1+exp(-w^T x)), where w refers to the parameters, X refers refers to the features. Since there is no closed form solution for w, you will need to use gradient descent or an alternative optimization approach to solve for the parameters.We use schoastic gradient descent to find the coefficients for the logistic regression model. Hence we use the below linear equations in our implementation. We also find the prediction using the following formula:\n",
    "    prediction=1/(1+exp(-w^T x))\n",
    "    b0 = b0 + alpha * (y – prediction) * prediction * (1 – prediction) * 1\n",
    "    b1 = b0 + alpha * (y – prediction) * prediction * (1 – prediction) * x1\n",
    "    b2 = b0 + alpha * (y – prediction) * prediction * (1 – prediction) * x2 </p>\n",
    "<p align> We also calculate the sigmoid values, and then find accuracy of our predicted output.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Our Algorithm\n",
    "def lr():\n",
    "    #Splitting the dataset in each fold into training and testing set\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "    #initialising coefficients, alpha and epoch\n",
    "    b0=0\n",
    "    b1=0\n",
    "    b2=0\n",
    "    alpha=0.3\n",
    "    epoch=1000\n",
    "    #running the loop for each row epoch times\n",
    "    for i in range(epoch):\n",
    "        for j in range(len(X_train)):\n",
    "            #calculating prediction and updating coefficient values\n",
    "            prediction=1 / (1 + np.exp(-(b0 + b1*X_train[j][0] + b2*X_train[j][1])))\n",
    "            b0 = b0 + alpha * (y_train[j]-prediction) * prediction * (1.0- prediction) * 1.0\n",
    "            b1= b1 + alpha * (y_train[j]-prediction) * prediction * (1.0- prediction) * X_train[j][0]\n",
    "            b2 = b2 + alpha * (y_train[j]-prediction) * prediction * (1.0- prediction) * X_train[j][1]         \n",
    "    coeff.append(b0)\n",
    "    coeff.append(b1)\n",
    "    coeff.append(b2)\n",
    "    #predicting based on test data\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        output=coeff[0]+coeff[1]*X_test[i][0]+coeff[2]*X_test[i][1]\n",
    "        sig=1.0/(1.0+np.exp(-output))\n",
    "        sigm.append(sig)\n",
    "    for i in range(len(sigm)):\n",
    "        if sigm[i]<=0.5:\n",
    "            sigm[i]=0\n",
    "        else:\n",
    "            sigm[i]=1\n",
    "    y_pred=np.array(sigm)\n",
    "    #calculating accuracy\n",
    "    correct = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] == y_pred[i]:\n",
    "            correct += 1\n",
    "    accuracy=correct / float(len(y_test)) * 100.0\n",
    "    accuracy_matrix.append(accuracy)\n",
    "    \n",
    "\n",
    "    \n",
    "    return accuracy_matrix,y_pred,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are splitting dataset to train and test and calling the logistic regression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#running for 5-folds\n",
    "for train,test in kf.split(X):\n",
    "    my_accuracy_matrix,my_y_pred,my_X_test=lr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are printing the maximum accuracy out of the 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.88311688311688\n"
     ]
    }
   ],
   "source": [
    "#we are taking maximum accuracy\n",
    "print(max(my_accuracy_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_ypred=my_y_pred[0:153]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<p align> This is about plotting the graph. We use the predicted values and plot the graph for the two features which we are using. Our graph is not very accurate. Both the classes are overlapping. We think that this is because of the dataset itself. We tried plotting the graph in scikit implementation also. We got the same plot. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7faa57279710>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa572eaa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos = where(final_ypred == 1)\n",
    "neg = where(final_ypred == 0)\n",
    "        \n",
    "plt.scatter(my_X_test[np.asarray(pos), 0], my_X_test[np.asarray(pos), 1], marker='o', c='b')\n",
    "plt.scatter(my_X_test[np.asarray(neg), 0], my_X_test[np.asarray(neg), 1], marker='x', c='r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
